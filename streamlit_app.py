#######################
# Import libraries
import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import plotly.express as px
import re
from datetime import date

#######################
# Page configuration
st.set_page_config(
    page_title="DAPA Contract Analysis",
    page_icon="ğŸ‚",
    layout="wide",
    initial_sidebar_state="expanded")
alt.themes.enable("default")

#######################
# CSS styling
st.markdown("""
<style>
[data-testid="block-container"] {
    padding-left: 2rem; padding-right: 2rem;
    padding-top: 1rem;  padding-bottom: 0rem;
    margin-bottom: -7rem;
}
[data-testid="stVerticalBlock"] { padding-left: 0rem; padding-right: 0rem; }

/* KPI ì¹´ë“œ í°ìƒ‰ */
[data-testid="stMetric"]{
    background-color:#ffffff; text-align:center; padding:15px 0;
    border:1px solid #eaeaea; border-radius:10px; color:#111111;
}
[data-testid="stMetricLabel"]{ display:flex; justify-content:center; align-items:center; }
[data-testid="stMetricDeltaIcon-Up"],[data-testid="stMetricDeltaIcon-Down"]{
    position:relative; left:38%; transform:translateX(-50%);
}

/* ì‘ì€ ì •ë³´ ìƒì & ê¸°ê°„ ë°°ì§€ */
.small-metric{
    background:#fff; border:1px solid #eaeaea; border-radius:10px;
    padding:10px 12px; line-height:1.25; font-size:0.9rem; overflow-wrap:anywhere;
}
.small-metric b{ font-size:0.95rem; }
.period-badge{
    display:inline-block; background:#f6f6f6; border:1px solid #eaeaea;
    border-radius:8px; padding:8px 10px; margin-bottom:10px; font-size:0.9rem;
}
</style>
""", unsafe_allow_html=True)

#######################
# Helpers
def get_slider_bounds(series: pd.Series, *, round_digits: int = 1,
                      floor_zero: bool = True, step: float = 0.1):
    """ì•ˆì „í•œ ìŠ¬ë¼ì´ë” ê²½ê³„ ê³„ì‚°"""
    s = pd.to_numeric(series, errors="coerce").dropna()
    if s.empty:
        return 0.0, 1.0, True
    mn = float(s.min())
    mx = float(s.max())
    if floor_zero:
        mn = max(0.0, mn)
    mn = round(mn, round_digits)
    mx = round(mx, round_digits)
    if not (mx > mn):
        mx = mn + step
    disabled = (s.nunique(dropna=True) < 2)
    return mn, mx, disabled

def fmt_total_amount_str(total_jo: float) -> str:
    """
    ì´ì•¡ í‘œê¸°: 0.1 ì¡°ì› ë¯¸ë§Œì´ë©´ ì–µì›ìœ¼ë¡œ, ì•„ë‹ˆë©´ ì¡°ì›ìœ¼ë¡œ.
    - ì…ë ¥ì€ 'ì¡°ì›' ë‹¨ìœ„ í•©ê³„(total_jo)
    """
    try:
        val = float(total_jo)
    except Exception:
        return "-"
    return f"{val*1e4:,.1f} ì–µì›" if val < 0.1 else f"{val:,.3f} ì¡°ì›"

#######################
# Load data
df_reshaped = pd.read_csv('data.csv', encoding='cp949')  # ë¶„ì„ ë°ì´í„° ë„£ê¸°

# ê³µí†µ ì „ì²˜ë¦¬: ìˆ«ì/ì—°ë„/ë‹¨ìœ„ ë³€í™˜
df_reshaped = df_reshaped.copy()
if "ê³„ì•½ê¸ˆì•¡" in df_reshaped.columns:
    df_reshaped["ê³„ì•½ê¸ˆì•¡"] = pd.to_numeric(df_reshaped["ê³„ì•½ê¸ˆì•¡"], errors="coerce")
else:
    df_reshaped["ê³„ì•½ê¸ˆì•¡"] = pd.NA

if "ê³„ì•½ì²´ê²°ì¼ì" in df_reshaped.columns:
    df_reshaped["_date"] = pd.to_datetime(df_reshaped["ê³„ì•½ì²´ê²°ì¼ì"], errors="coerce")
    df_reshaped["_year"] = df_reshaped["_date"].dt.year
else:
    df_reshaped["_date"] = pd.NaT
    df_reshaped["_year"] = pd.NA

# ë‹¨ìœ„ ì»¬ëŸ¼
df_reshaped["ê³„ì•½ê¸ˆì•¡_ì–µì›"] = df_reshaped["ê³„ì•½ê¸ˆì•¡"] / 1e8
df_reshaped["ê³„ì•½ê¸ˆì•¡_ì¡°ì›"] = df_reshaped["ê³„ì•½ê¸ˆì•¡"] / 1e12

# ----------------------------
# ê³„ì•½ê¸°ê°„ íŒŒì‹±(ë‹¨ë…„/ë‹¤ë…„ êµ¬ë¶„ìš©)
# ----------------------------
df_reshaped["_p_start"] = pd.NaT
df_reshaped["_p_end"] = pd.NaT

# 1) "ê³„ì•½ê¸°ê°„" ë¬¸ìì—´ ì•ˆì— "ì‹œì‘ ~ ì¢…ë£Œ"
if "ê³„ì•½ê¸°ê°„" in df_reshaped.columns:
    parts = df_reshaped["ê³„ì•½ê¸°ê°„"].astype(str).str.split("~")
    df_reshaped["_p_start"] = pd.to_datetime(parts.str[0].str.strip(), errors="coerce")
    df_reshaped["_p_end"]   = pd.to_datetime(parts.str[1].str.strip(), errors="coerce")

# 2) ë³„ë„ ì‹œì‘/ì¢…ë£Œ ì»¬ëŸ¼ ë³´ì •
for c_from, c_to in [("ê³„ì•½ê¸°ê°„ì‹œì‘ì¼ì","_p_start"), ("ê³„ì•½ê¸°ê°„ì¢…ë£Œì¼ì","_p_end")]:
    if c_from in df_reshaped.columns:
        df_reshaped[c_to] = pd.to_datetime(df_reshaped[c_from], errors="coerce")

# ê¸°ê°„(ì¼ìˆ˜)
mask = df_reshaped[["_p_start","_p_end"]].notna().all(axis=1)
df_reshaped["_p_days"] = pd.NA
df_reshaped.loc[mask, "_p_days"] = (df_reshaped.loc[mask, "_p_end"] - df_reshaped.loc[mask, "_p_start"]).dt.days + 1

# ê¸°ê°„ êµ¬ë¶„(ë‹¨ë…„/ë‹¤ë…„(në…„))
df_reshaped["ê¸°ê°„êµ¬ë¶„"] = "ê¸°ê°„ì •ë³´ì—†ìŒ"
days = pd.to_numeric(df_reshaped["_p_days"], errors="coerce")
ny = np.ceil(days / 365.0)

df_reshaped.loc[days.notna() & (days <= 365), "ê¸°ê°„êµ¬ë¶„"] = "ë‹¨ë…„(â‰¤1ë…„)"
multi_years = ny[days > 365].astype("Int64").astype(str)
df_reshaped.loc[days > 365, "ê¸°ê°„êµ¬ë¶„"] = "ë‹¤ë…„(" + multi_years + "ë…„)"

#######################
# Sidebar
with st.sidebar:
    st.title("êµ­ë°© ê³„ì•½ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.caption("í•„í„°ì™€ í‚¤ì›Œë“œë¥¼ ì¡°í•©í•´ ì›í•˜ëŠ” ê³„ì•½ë§Œ ì¢í˜€ë³´ì„¸ìš”.")

    df = df_reshaped.copy()

    # ------------ í•„í„° UI ------------
    years = sorted([int(y) for y in df["_year"].dropna().unique()]) if df["_year"].notna().any() else []
    year_sel = st.selectbox("ì—°ë„ ì„ íƒ (Î”ëŠ” ì—°ë„ ì„ íƒ ì‹œ í‘œì‹œ)", options=["ì „ì²´"] + years, index=0)

    type_options = sorted([x for x in df.get("ì—…ë¬´êµ¬ë¶„ëª…", pd.Series(dtype=str)).dropna().unique()])
    type_sel = st.multiselect("ì—…ë¬´êµ¬ë¶„ ì„ íƒ", options=type_options, default=[])

    method_options = sorted([x for x in df.get("ê³„ì•½ì²´ê²°ë°©ë²•ëª…", pd.Series(dtype=str)).dropna().unique()])
    method_sel = st.multiselect("ê³„ì•½ë°©ë²• ì„ íƒ", options=method_options, default=[])

    # ğŸ’° ê¸ˆì•¡ ìŠ¬ë¼ì´ë”: ì–µì› (ì•ˆì „ ì²˜ë¦¬)
    amt_min, amt_max, amt_disabled = get_slider_bounds(df["ê³„ì•½ê¸ˆì•¡_ì–µì›"], round_digits=1, floor_zero=True, step=0.1)
    amt_range = st.slider(
        "ê³„ì•½ê¸ˆì•¡ ë²”ìœ„ (ì–µì›)",
        min_value=float(amt_min),
        max_value=float(amt_max),
        value=(float(amt_min), float(amt_max)),
        step=0.1,
        disabled=amt_disabled,
    )

    st.markdown("---")

    # ------------ í‚¤ì›Œë“œ ê²€ìƒ‰ ------------
    keyword = st.text_input("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰", placeholder="ê³„ì•½ëª…, ìˆ˜ìš”ê¸°ê´€ëª…, ëŒ€í‘œì—…ì²´ëª…, ì£¼ì†Œ ë“±")
    match_mode = st.radio("ì¼ì¹˜ ë°©ì‹", ["AND (ëª¨ë‘ í¬í•¨)", "OR (í•˜ë‚˜ë¼ë„ í¬í•¨)"], horizontal=True)

    search_cols = [c for c in ["ê³„ì•½ëª…", "ìˆ˜ìš”ê¸°ê´€ëª…", "ëŒ€í‘œì—…ì²´ëª…", "ëŒ€í‘œì—…ì²´ì£¼ì†Œ", "ì—…ë¬´êµ¬ë¶„ëª…", "ê³„ì•½ì²´ê²°ë°©ë²•ëª…"] if c in df.columns]
    if search_cols:
        if "search_text" not in df.columns:
            df["search_text"] = (
                df[search_cols].astype(str).fillna("").agg(" ".join, axis=1).str.lower()
            )
    else:
        df["search_text"] = ""

    # ------------ í•„í„° ì ìš© ------------
    filtered = df.copy()
    if year_sel != "ì „ì²´":
        filtered = filtered[filtered["_year"] == int(year_sel)]
    if type_sel:
        filtered = filtered[filtered["ì—…ë¬´êµ¬ë¶„ëª…"].isin(type_sel)]
    if method_sel:
        filtered = filtered[filtered["ê³„ì•½ì²´ê²°ë°©ë²•ëª…"].isin(method_sel)]
    if filtered["ê³„ì•½ê¸ˆì•¡_ì–µì›"].notna().any():
        filtered = filtered[(filtered["ê³„ì•½ê¸ˆì•¡_ì–µì›"] >= amt_range[0]) & (filtered["ê³„ì•½ê¸ˆì•¡_ì–µì›"] <= amt_range[1])]

    if keyword.strip():
        tokens = [t for t in keyword.lower().split() if t]
        if tokens:
            if match_mode.startswith("AND"):
                for t in tokens:
                    filtered = filtered[filtered["search_text"].str.contains(re.escape(t), na=False)]
            else:
                pattern = "|".join(map(re.escape, tokens))
                filtered = filtered[filtered["search_text"].str.contains(pattern, na=False)]

    filtered = filtered.drop(columns=["search_text"], errors="ignore")
    st.session_state["filtered_df"] = filtered

    # Î” ê³„ì‚°(ì—°ë„ ì„ íƒ ì‹œ)
    prev_year_sum_jo = None
    if year_sel != "ì „ì²´":
        y = int(year_sel)
        prev_df = df.copy()
        prev_df = prev_df[prev_df["_year"] == (y - 1)]
        if type_sel:
            prev_df = prev_df[prev_df["ì—…ë¬´êµ¬ë¶„ëª…"].isin(type_sel)]
        if method_sel:
            prev_df = prev_df[prev_df["ê³„ì•½ì²´ê²°ë°©ë²•ëª…"].isin(method_sel)]
        if prev_df["ê³„ì•½ê¸ˆì•¡_ì–µì›"].notna().any():
            prev_df = prev_df[(prev_df["ê³„ì•½ê¸ˆì•¡_ì–µì›"] >= amt_range[0]) & (prev_df["ê³„ì•½ê¸ˆì•¡_ì–µì›"] <= amt_range[1])]
        if keyword.strip():
            if "search_text" not in prev_df.columns:
                prev_df["search_text"] = (
                    prev_df[search_cols].astype(str).fillna("").agg(" ".join, axis=1).str.lower()
                    if search_cols else ""
                )
            tokens = [t for t in keyword.lower().split() if t]
            if tokens:
                if match_mode.startswith("AND"):
                    for t in tokens:
                        prev_df = prev_df[prev_df["search_text"].str.contains(re.escape(t), na=False)]
                else:
                    pattern = "|".join(map(re.escape, tokens))
                    prev_df = prev_df[prev_df["search_text"].str.contains(pattern, na=False)]
            prev_df = prev_df.drop(columns=["search_text"], errors="ignore")
        prev_year_sum_jo = float(prev_df["ê³„ì•½ê¸ˆì•¡_ì¡°ì›"].sum()) if "ê³„ì•½ê¸ˆì•¡_ì¡°ì›" in prev_df.columns else 0.0

    # ì‚¬ì´ë“œë°” ìš”ì•½ ë°°ì§€ (ì´ì•¡ ë‹¨ìœ„ ìë™ ì „í™˜)
    if "_date" in filtered.columns and filtered["_date"].notna().any():
        start_dt = pd.to_datetime(filtered["_date"].min()).date()
        end_dt   = pd.to_datetime(filtered["_date"].max()).date()
        total_jo = float(filtered["ê³„ì•½ê¸ˆì•¡_ì¡°ì›"].sum()) if filtered["ê³„ì•½ê¸ˆì•¡_ì¡°ì›"].notna().any() else 0.0
        total_str = fmt_total_amount_str(total_jo)
        st.success(f"ê¸°ê°„: {start_dt} ~ {end_dt} | ì´ì•¡: {total_str} | ê±´ìˆ˜: {len(filtered):,}ê±´")
    else:
        total_jo = float(filtered["ê³„ì•½ê¸ˆì•¡_ì¡°ì›"].sum()) if "ê³„ì•½ê¸ˆì•¡_ì¡°ì›" in filtered.columns else 0.0
        total_str = fmt_total_amount_str(total_jo)
        st.success(f"ê¸°ê°„: ë°ì´í„° ì—†ìŒ | ì´ì•¡: {total_str} | ê±´ìˆ˜: {len(filtered):,}ê±´")

#######################
# Dashboard Main Panel
col = st.columns((1.5, 4.5, 2), gap='medium')

# =======================
# ì»¬ëŸ¼ 0: KPI + ê¸°ê°„
# =======================
with col[0]:
    st.markdown("### ğŸ“Œ í•µì‹¬ ì§€í‘œ")

    data = st.session_state.get("filtered_df", df_reshaped).copy()

    # ê¸°ê°„ ë°°ì§€
    if "_date" in data.columns and data["_date"].notna().any():
        start_dt = pd.to_datetime(data["_date"].min()).date()
        end_dt   = pd.to_datetime(data["_date"].max()).date()
        st.markdown(f"<div class='period-badge'>ê¸°ê°„: <b>{start_dt}</b> ~ <b>{end_dt}</b></div>", unsafe_allow_html=True)
    else:
        st.markdown("<div class='period-badge'>ê¸°ê°„: ë°ì´í„° ì—†ìŒ</div>", unsafe_allow_html=True)

    # KPI
    total_jo = data["ê³„ì•½ê¸ˆì•¡_ì¡°ì›"].sum(skipna=True)
    avg_eok  = data["ê³„ì•½ê¸ˆì•¡_ì–µì›"].mean(skipna=True)
    cnt      = len(data)

    delta_str = None
    if year_sel != "ì „ì²´" and 'prev_year_sum_jo' in locals() and prev_year_sum_jo is not None:
        prev = prev_year_sum_jo
        if prev and prev > 0:
            delta_pct = (total_jo - prev) / prev * 100.0
            delta_str = f"{delta_pct:+.1f}%"
        else:
            delta_str = "â€“"

    # âœ… ì´ ê³„ì•½ ê¸ˆì•¡: 0.1ì¡° ë¯¸ë§Œì´ë©´ 'ì–µì›', ì•„ë‹ˆë©´ 'ì¡°ì›'
    total_display = fmt_total_amount_str(float(total_jo))
    st.metric("ì´ ê³„ì•½ ê¸ˆì•¡", total_display, delta=delta_str if delta_str else None)
    st.metric("í‰ê·  ê³„ì•½ ê¸ˆì•¡", f"{avg_eok:,.1f} ì–µì›" if pd.notna(avg_eok) else "-")
    st.metric("ê³„ì•½ ê±´ìˆ˜", f"{cnt:,} ê±´")

    if "ëŒ€í‘œì—…ì²´ëª…" in data.columns and not data.empty:
        top_vendor_name = (
            data.groupby("ëŒ€í‘œì—…ì²´ëª…")["ê³„ì•½ê¸ˆì•¡_ì–µì›"].sum().sort_values(ascending=False).index[0]
        )
        st.markdown(f"<div class='small-metric'>ìµœëŒ€ ê³„ì•½ ì—…ì²´(ì´ì•¡ê¸°ì¤€)<br><b>{top_vendor_name}</b></div>", unsafe_allow_html=True)

# =======================
# ì»¬ëŸ¼ 1: ê²€ìƒ‰/í•„í„° ê²°ê³¼ í…Œì´ë¸” + ê³„ì•½ë°©ë²• Breakdown + íˆíŠ¸ë§µ + ê¸°ê°„í†µê³„(ê°„ë‹¨)
# =======================
with col[1]:
    st.markdown("### ğŸ” ê²€ìƒ‰/í•„í„° ê²°ê³¼ (í…Œì´ë¸”)")
    base = st.session_state.get("filtered_df", df_reshaped).copy()

    # ë¯¸ë‹ˆí•„í„° (ì•ˆì „ ìŠ¬ë¼ì´ë” ì ìš©)
    with st.expander("í…Œì´ë¸” ì¶”ê°€ í•„í„°", expanded=False):
        q_name   = st.text_input("ê³„ì•½ëª… ê²€ìƒ‰", placeholder="ì˜ˆ: ë””ìŠ¤í”Œë ˆì´, ì—°êµ¬ ìš©ì—­ ë“±")
        q_vendor = st.text_input("ì—…ì²´ ê²€ìƒ‰", placeholder="ì˜ˆ: ãˆœâ—‹â—‹, ìœ í•œíšŒì‚¬ â—‹â—‹ ë“±")
        q_org    = st.text_input("ìˆ˜ìš”ê¸°ê´€ ê²€ìƒ‰", placeholder="ì˜ˆ: í•´êµ°, ìœ¡êµ°ë³¸ë¶€ ë“±")
        eok_min, eok_max, eok_disabled = get_slider_bounds(base["ê³„ì•½ê¸ˆì•¡_ì–µì›"], round_digits=1, floor_zero=True, step=0.1)
        eok_range = st.slider(
            "ê³„ì•½ê¸ˆì•¡(ì–µì›) ë²”ìœ„(í…Œì´ë¸”)",
            min_value=float(eok_min),
            max_value=float(eok_max),
            value=(float(eok_min), float(eok_max)),
            step=0.1,
            disabled=eok_disabled,
        )

    table_df = base.copy()
    if q_name.strip() and "ê³„ì•½ëª…" in table_df.columns:
        table_df = table_df[table_df["ê³„ì•½ëª…"].astype(str).str.contains(q_name, case=False, na=False)]
    if q_vendor.strip() and "ëŒ€í‘œì—…ì²´ëª…" in table_df.columns:
        table_df = table_df[table_df["ëŒ€í‘œì—…ì²´ëª…"].astype(str).str.contains(q_vendor, case=False, na=False)]
    if q_org.strip() and "ìˆ˜ìš”ê¸°ê´€ëª…" in table_df.columns:
        table_df = table_df[table_df["ìˆ˜ìš”ê¸°ê´€ëª…"].astype(str).str.contains(q_org, case=False, na=False)]
    if table_df["ê³„ì•½ê¸ˆì•¡_ì–µì›"].notna().any():
        table_df = table_df[(table_df["ê³„ì•½ê¸ˆì•¡_ì–µì›"] >= eok_range[0]) & (table_df["ê³„ì•½ê¸ˆì•¡_ì–µì›"] <= eok_range[1])]

    # ê¸ˆì•¡ ì •ë ¬ + í‘œì‹œ ê±´ìˆ˜
    sort_dir = st.radio("ê¸ˆì•¡ ì •ë ¬", ["ë‚´ë¦¼ì°¨ìˆœ(ë†’ì€â†’ë‚®ì€)", "ì˜¤ë¦„ì°¨ìˆœ(ë‚®ì€â†’ë†’ì€)"],
                        horizontal=True, index=0)
    rows_opt = [50, 100, 200, 500, 1000]
    rows_to_show = st.selectbox("í‘œì‹œ ê±´ìˆ˜(ê¸ˆì•¡ ê¸°ì¤€ ìƒìœ„ Nê±´)", rows_opt, index=2)

    if "ê³„ì•½ê¸ˆì•¡_ì–µì›" in table_df.columns:
        table_df = table_df.sort_values(by="ê³„ì•½ê¸ˆì•¡_ì–µì›",
                                        ascending=(sort_dir.startswith("ì˜¤ë¦„")),
                                        na_position="last")

    show_cols = [c for c in ["ê³„ì•½ì²´ê²°ì¼ì","ê³„ì•½ëª…","ê³„ì•½ê¸ˆì•¡_ì–µì›","ëŒ€í‘œì—…ì²´ëª…","ìˆ˜ìš”ê¸°ê´€ëª…","ì—…ë¬´êµ¬ë¶„ëª…","ê³„ì•½ì²´ê²°ë°©ë²•ëª…","ê³„ì•½ê¸°ê°„"] if c in table_df.columns]
    if "ê³„ì•½ê¸ˆì•¡_ì–µì›" in show_cols:
        table_df = table_df.rename(columns={"ê³„ì•½ê¸ˆì•¡_ì–µì›":"ê³„ì•½ê¸ˆì•¡(ì–µì›)"})
    if show_cols:
        show_cols = [c if c!="ê³„ì•½ê¸ˆì•¡_ì–µì›" else "ê³„ì•½ê¸ˆì•¡(ì–µì›)" for c in show_cols]
        table_df_display = table_df[show_cols]
        st.dataframe(
            table_df_display.head(rows_to_show),
            use_container_width=True,
            hide_index=True,
            column_config={
                "ê³„ì•½ì²´ê²°ì¼ì": st.column_config.DatetimeColumn(format="YYYY-MM-DD"),
                "ê³„ì•½ê¸ˆì•¡(ì–µì›)": st.column_config.NumberColumn(format="%.1f"),
            }
        )
        csv = table_df_display.to_csv(index=False).encode("utf-8-sig")
        st.download_button("â¬‡ï¸ í˜„ì¬ í‘œ ë‹¤ìš´ë¡œë“œ (CSV)", data=csv, file_name="filtered_contracts.csv", mime="text/csv")
    else:
        st.info("í‘œì‹œí•  ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ğŸ“Š ê³„ì•½ë°©ë²• Breakdown
    st.subheader("ğŸ“Š ê³„ì•½ë°©ë²• Breakdown (ì–µì›)")
    if "ê³„ì•½ì²´ê²°ë°©ë²•ëª…" in base.columns and not base.empty:
        method_summary = base.groupby("ê³„ì•½ì²´ê²°ë°©ë²•ëª…")["ê³„ì•½ê¸ˆì•¡_ì–µì›"].sum().reset_index()
        if not method_summary.empty:
            fig_method = px.pie(
                method_summary, names="ê³„ì•½ì²´ê²°ë°©ë²•ëª…", values="ê³„ì•½ê¸ˆì•¡_ì–µì›",
                title="ê³„ì•½ë°©ë²•ë³„ ê³„ì•½ê¸ˆì•¡ ë¹„ìœ¨(ì–µì›)"
            )
            st.plotly_chart(fig_method, use_container_width=True)
        else:
            st.info("í‘œì‹œí•  ê³„ì•½ë°©ë²• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ê³„ì•½ë°©ë²•ëª… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ğŸ›ï¸ íˆíŠ¸ë§µ (ë¼ë²¨ í¬í•¨)
    st.subheader("ğŸ“Š ì—°ë„ Ã— ê³„ì•½ë°©ë²• íˆíŠ¸ë§µ (ì–µì›, ë¼ë²¨)")
    if "ê³„ì•½ì²´ê²°ë°©ë²•ëª…" in base.columns and "_year" in base.columns:
        pivot_df = base.groupby(["_year","ê³„ì•½ì²´ê²°ë°©ë²•ëª…"])["ê³„ì•½ê¸ˆì•¡_ì–µì›"].sum().reset_index()
        if not pivot_df.empty:
            base_chart = alt.Chart(pivot_df).encode(
                x=alt.X("ê³„ì•½ì²´ê²°ë°©ë²•ëª…:N", title="ê³„ì•½ ë°©ë²•"),
                y=alt.Y("_year:O", title="ì—°ë„"),
            )
            heat_rect = base_chart.mark_rect().encode(
                color=alt.Color("ê³„ì•½ê¸ˆì•¡_ì–µì›:Q", title="ê¸ˆì•¡(ì–µì›)", scale=alt.Scale(scheme="blues")),
                tooltip=[alt.Tooltip("_year:O", title="ì—°ë„"),
                         alt.Tooltip("ê³„ì•½ì²´ê²°ë°©ë²•ëª…:N", title="ë°©ë²•"),
                         alt.Tooltip("ê³„ì•½ê¸ˆì•¡_ì–µì›:Q", title="ê¸ˆì•¡(ì–µì›)", format=".1f")]
            )
            heat_text = base_chart.mark_text(baseline="middle").encode(
                text=alt.Text("ê³„ì•½ê¸ˆì•¡_ì–µì›:Q", format=".1f"),
                color=alt.value("#222")
            )
            st.altair_chart((heat_rect + heat_text).properties(width="container", height=360),
                            use_container_width=True)
        else:
            st.info("í‘œì‹œí•  íˆíŠ¸ë§µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ê³„ì•½ì²´ê²°ë°©ë²•ëª… / ì—°ë„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ íˆíŠ¸ë§µ í‘œì‹œ ë¶ˆê°€")

    st.markdown("---")

    # â±ï¸ ê³„ì•½ê¸°ê°„ í†µê³„ (ê°„ë‹¨ í‘œ + ìµœì¥ê¸°ê°„ ìƒìœ„ Nê±´)
    st.subheader("â±ï¸ ê³„ì•½ê¸°ê°„ í†µê³„")
    period_base = base.copy()
    if "ê¸°ê°„êµ¬ë¶„" in period_base.columns:
        # ë‹¨ë…„/ë‹¤ë…„ ëŒ€ë¶„ë¥˜
        cat = period_base["ê¸°ê°„êµ¬ë¶„"].astype(str)
        big = np.where(cat.str.startswith("ë‹¤ë…„("), "ë‹¤ë…„", np.where(cat.eq("ë‹¨ë…„(â‰¤1ë…„)"), "ë‹¨ë…„", "ê¸°ê°„ì •ë³´ì—†ìŒ"))
        period_base["ê¸°ê°„ëŒ€ë¶„ë¥˜"] = big

        # ë‹¨ë…„/ë‹¤ë…„ ê³„ì•½ê±´ìˆ˜ í‘œ
        order = ["ë‹¨ë…„", "ë‹¤ë…„", "ê¸°ê°„ì •ë³´ì—†ìŒ"]
        cnt_df = (period_base.groupby("ê¸°ê°„ëŒ€ë¶„ë¥˜")
                  .size().reindex(order).reset_index(name="ê³„ì•½ê±´ìˆ˜").dropna())
        st.dataframe(cnt_df, use_container_width=True, hide_index=True)

        # ìµœì¥ê¸°ê°„ ìƒìœ„ Nê±´ ëª©ë¡
        top_n = st.selectbox("ğŸ“œ ê³„ì•½ê¸°ê°„ì´ ê¸´ ìƒìœ„ Nê±´", [5, 10, 20, 50], index=1)
        dur_df = period_base.copy()
        dur_df["_p_days_num"] = pd.to_numeric(dur_df["_p_days"], errors="coerce")
        long_df = (dur_df.dropna(subset=["_p_days_num"])
                   .sort_values("_p_days_num", ascending=False)
                   .head(top_n))

        if not long_df.empty:
            show_cols2 = []
            for c in ["ê³„ì•½ëª…","ëŒ€í‘œì—…ì²´ëª…","ìˆ˜ìš”ê¸°ê´€ëª…"]:
                if c in long_df.columns: show_cols2.append(c)
            long_df = long_df.assign(
                ì‹œì‘ì¼=pd.to_datetime(long_df["_p_start"]).dt.date,
                ì¢…ë£Œì¼=pd.to_datetime(long_df["_p_end"]).dt.date,
                ê¸°ê°„_ì¼ìˆ˜=long_df["_p_days_num"].astype(int),
                ê¸°ê°„_ë…„ìˆ˜=(long_df["_p_days_num"]/365.0).round(1),
                ê³„ì•½ê¸ˆì•¡_ì–µì›_round=long_df.get("ê³„ì•½ê¸ˆì•¡_ì–µì›", pd.Series(dtype=float)).round(1)
            )
            show_cols2 += ["ì‹œì‘ì¼","ì¢…ë£Œì¼","ê¸°ê°„_ì¼ìˆ˜","ê¸°ê°„_ë…„ìˆ˜"]
            if "ê³„ì•½ê¸ˆì•¡_ì–µì›_round" in long_df.columns:
                long_df = long_df.rename(columns={"ê³„ì•½ê¸ˆì•¡_ì–µì›_round":"ê³„ì•½ê¸ˆì•¡(ì–µì›)"})
                show_cols2 += ["ê³„ì•½ê¸ˆì•¡(ì–µì›)"]

            st.dataframe(long_df[show_cols2], use_container_width=True, hide_index=True)
        else:
            st.info("ê³„ì•½ê¸°ê°„ ì •ë³´ë¥¼ ê°€ì§„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ê³„ì•½ê¸°ê°„ ì •ë³´ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ì–´ í†µê³„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# =======================
# ì»¬ëŸ¼ 2: ğŸ† ìˆœìœ„ë§Œ í‘œì‹œ
# =======================
with col[2]:
    st.markdown("### ğŸ† ìˆœìœ„")
    data = st.session_state.get("filtered_df", df_reshaped).copy()

    # Top ìˆ˜ìš”ê¸°ê´€
    st.subheader("ğŸ¢ Top ìˆ˜ìš”ê¸°ê´€ (ì–µì›)")
    if "ìˆ˜ìš”ê¸°ê´€ëª…" in data.columns and not data.empty:
        top_org = (data.groupby("ìˆ˜ìš”ê¸°ê´€ëª…")["ê³„ì•½ê¸ˆì•¡_ì–µì›"].sum().reset_index()
                   .sort_values("ê³„ì•½ê¸ˆì•¡_ì–µì›", ascending=False).head(10))
        if not top_org.empty:
            fig_org = px.bar(top_org, x="ê³„ì•½ê¸ˆì•¡_ì–µì›", y="ìˆ˜ìš”ê¸°ê´€ëª…", orientation="h",
                             labels={"ê³„ì•½ê¸ˆì•¡_ì–µì›":"ê³„ì•½ ê¸ˆì•¡(ì–µì›)","ìˆ˜ìš”ê¸°ê´€ëª…":"ê¸°ê´€"},
                             title="ìƒìœ„ 10ê°œ ìˆ˜ìš”ê¸°ê´€")
            fig_org.update_layout(yaxis=dict(autorange="reversed"))
            st.plotly_chart(fig_org, use_container_width=True)
        else:
            st.info("í‘œì‹œí•  ìˆ˜ìš”ê¸°ê´€ ìˆœìœ„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ìˆ˜ìš”ê¸°ê´€ëª… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # Top ì—…ì²´ (ê¸ˆì•¡)
    st.subheader("ğŸ­ Top ì—…ì²´ (ê¸ˆì•¡ ê¸°ì¤€ ìƒìœ„ 10)")
    if "ëŒ€í‘œì—…ì²´ëª…" in data.columns and not data.empty:
        top_vendor_amt = (data.groupby("ëŒ€í‘œì—…ì²´ëª…")["ê³„ì•½ê¸ˆì•¡_ì–µì›"].sum().reset_index()
                          .sort_values("ê³„ì•½ê¸ˆì•¡_ì–µì›", ascending=False).head(10))
        if not top_vendor_amt.empty:
            fig_vendor_amt = px.bar(top_vendor_amt, x="ê³„ì•½ê¸ˆì•¡_ì–µì›", y="ëŒ€í‘œì—…ì²´ëª…", orientation="h",
                                    labels={"ê³„ì•½ê¸ˆì•¡_ì–µì›":"ê³„ì•½ ê¸ˆì•¡(ì–µì›)","ëŒ€í‘œì—…ì²´ëª…":"ì—…ì²´"},
                                    title="ìƒìœ„ 10ê°œ ì—…ì²´ (ê¸ˆì•¡)")
            fig_vendor_amt.update_layout(yaxis=dict(autorange="reversed"))
            st.plotly_chart(fig_vendor_amt, use_container_width=True)
        else:
            st.info("í‘œì‹œí•  ì—…ì²´ ìˆœìœ„(ê¸ˆì•¡) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ëŒ€í‘œì—…ì²´ëª… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ğŸ”¹ Top ì—…ì²´ (ê±´ìˆ˜)
    st.subheader("ğŸ­ Top ì—…ì²´ (ê±´ìˆ˜ ê¸°ì¤€ ìƒìœ„ 10)")
    if "ëŒ€í‘œì—…ì²´ëª…" in data.columns and not data.empty:
        top_vendor_cnt = (data.groupby("ëŒ€í‘œì—…ì²´ëª…").size()
                          .reset_index(name="ê³„ì•½ê±´ìˆ˜")
                          .sort_values("ê³„ì•½ê±´ìˆ˜", ascending=False).head(10))
        if not top_vendor_cnt.empty:
            fig_vendor_cnt = px.bar(top_vendor_cnt, x="ê³„ì•½ê±´ìˆ˜", y="ëŒ€í‘œì—…ì²´ëª…", orientation="h",
                                    labels={"ê³„ì•½ê±´ìˆ˜":"ê±´ìˆ˜","ëŒ€í‘œì—…ì²´ëª…":"ì—…ì²´"},
                                    title="ìƒìœ„ 10ê°œ ì—…ì²´ (ê±´ìˆ˜)")
            fig_vendor_cnt.update_layout(yaxis=dict(autorange="reversed"))
            st.plotly_chart(fig_vendor_cnt, use_container_width=True)
        else:
            st.info("í‘œì‹œí•  ì—…ì²´ ìˆœìœ„(ê±´ìˆ˜) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ëŒ€í‘œì—…ì²´ëª… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

#######################
# ğŸ“ ë¶€ë¡: ì›ë³¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (í˜ì´ì§€ ìµœí•˜ë‹¨)
#######################
st.markdown("---")
st.markdown("### ğŸ“ ë¶€ë¡: ì›ë³¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
raw_csv = df_reshaped.to_csv(index=False).encode("utf-8-sig")
st.download_button("ì›ë³¸ CSV ë‹¤ìš´ë¡œë“œ", data=raw_csv, file_name="raw_data_original.csv", mime="text/csv")
